{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ρ = 0.1 # initialize ro\n",
    "n = 1000 # sample size\n",
    "p = 20 # dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n, p, ρ, r, β, duplication):\n",
    "    X = torch.zeros((duplication, n, p))\n",
    "    i = torch.arange(p).view(-1, 1)\n",
    "    j = torch.arange(p).view(1, -1)\n",
    "    \n",
    "    Σ = torch.pow(ρ, torch.abs(i - j).float())\n",
    "    L = torch.linalg.cholesky(Σ)\n",
    "    Z = torch.randn(duplication, n, p)\n",
    "    X = Z @ torch.transpose(L, 1, 0)\n",
    "    \n",
    "    σ = (1-r)/r * (β.T @ Σ @ β)\n",
    "    \n",
    "    ε = torch.randn(n) * torch.sqrt(σ)\n",
    "    \n",
    "    Y = X @ β + ε\n",
    "    \n",
    "    return X, Y, {\n",
    "        'Σ': Σ,\n",
    "        'ε': ε\n",
    "    }   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4932/253544527.py:11: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)\n",
      "  σ = (1-r)/r * (β.T @ Σ @ β)\n"
     ]
    }
   ],
   "source": [
    "X, Y, other = generate_dataset(n=100, p=10, ρ=0, β=torch.ones(10), r=0.8, duplication=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "xtx = X.permute(0, 2, 1)@X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 10, 10])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "from torch.nn.functional import mse_loss, l1_loss\n",
    "from tqdm import tqdm\n",
    "\n",
    "def lasso(λ, epochs=800):\n",
    "    β = torch.randn((1000, 10, 1), device='cuda', requires_grad=True)\n",
    "    optimizer = Adam([β], lr=0.005)\n",
    "    loss_l = torch.zeros(epochs)\n",
    "    ones = torch.ones((1000, 1), device='cuda')\n",
    "    # pbar = tqdm(total=epochs, desc='LASSO')\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        mse = torch.mean(((Y-X@β)**2), dim=1)\n",
    "        l1norm = torch.sum(β.abs(), dim=1)\n",
    "        # print(mse.shape, l1norm.shape)\n",
    "        loss = mse + λ*l1norm\n",
    "        loss.backward(ones)\n",
    "        loss_l[epoch] = loss[-1]\n",
    "        # pbar.set_postfix_str(f'loss: {loss}')\n",
    "        # pbar.update()\n",
    "        optimizer.step()\n",
    "    rss = torch.sum(((Y-X@β)**2), dim=1).squeeze(-1)\n",
    "    k = (β.abs() > 1e-5).sum()\n",
    "    aic = 100 * torch.log(rss*0.01) + torch.full(size=(1000, ), fill_value=2*k, device='cuda')\n",
    "    bic = 100 * torch.log(rss*0.01) + torch.full(size=(1000, ), fill_value=torch.log(torch.tensor(100))*k, device='cuda')\n",
    "    \n",
    "    return β, loss_l, aic, bic, rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge(λ):\n",
    "    # closed form solution\n",
    "    \n",
    "    global X, xtx, Y\n",
    "    if xtx.device != 'cuda':\n",
    "        xtx = xtx.to('cuda')\n",
    "    if Y.device != 'cuda':\n",
    "        Y = Y.to('cuda')\n",
    "    if X.device != 'cuda':\n",
    "        X = X.to('cuda')\n",
    "    β = torch.linalg.solve(xtx + λ * torch.eye(xtx.shape[-1], device='cuda'), X.permute(0, 2, 1)@Y)\n",
    "    \n",
    "    # report AIC, BIC\n",
    "    rss = torch.sum(((Y-X@β)**2), dim=1).squeeze(-1)\n",
    "    k = (β.abs() > 1e-5).sum()\n",
    "    aic = 100 * torch.log(rss*0.01) + torch.full(size=(1000, ), fill_value=2*k, device='cuda')\n",
    "    bic = 100 * torch.log(rss*0.01) + torch.full(size=(1000, ), fill_value=torch.log(torch.tensor(100))*k, device='cuda')\n",
    "    \n",
    "    return β, aic, bic\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "λ:   0%|          | 0/10 [00:27<?, ?it/s]\n",
      "λ: 100%|██████████| 10/10 [00:15<00:00,  1.51s/it, λ=tensor(0.1000)]"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(total=10, desc='λ')\n",
    "for λ in torch.linspace(0, 0.1, 10):\n",
    "    ridge_beta, ridge_aic, ridge_bic = ridge(λ)\n",
    "    lasso_beta, loss, lasso_aic, lasso_bic, rss = lasso(λ)\n",
    "    pbar.set_postfix_str(f'{λ=}')\n",
    "    pbar.update()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "590d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
